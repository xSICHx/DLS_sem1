{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20320,"databundleVersionId":1134053,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"Xw7YkEefehWo","cell_type":"markdown","source":"# Домашнее задание. Классификация изображений\n\nСегодня вам предстоить помочь телекомпании FOX в обработке их контента. Как вы знаете, сериал \"Симпсоны\" идет на телеэкранах более 25 лет, и за это время скопилось очень много видеоматериала. Персоонажи менялись вместе с изменяющимися графическими технологиями, и Гомер Симпсон-2018 не очень похож на Гомера Симпсона-1989. В этом задании вам необходимо классифицировать персонажей, проживающих в Спрингфилде. Думаю, нет смысла представлять каждого из них в отдельности.\n\n","metadata":{"id":"Xw7YkEefehWo"}},{"id":"ZQ_3zjLMmzQ0","cell_type":"markdown","source":"## Идеи\n\n### Аугментация\n\n\n[X] Хочется увеличить количество данных. Поэтому флип, ротате, увеличения яркостей\n\n[ ] Сделать одинкаовое количество фоточек во всех классах через аугментации\n\n### Кроссвалидация\n\n[ ] Сделать вместо разделения на train, valid, кроссвалидацию и сохранить ансамблем.\n\n\n### Модели\n\n[X] ResNet18 с заморозкой первых слоев\n\n[ ] ResNet с ограничением обучения первых слоев\n","metadata":{"id":"ZQ_3zjLMmzQ0"}},{"id":"n7ivommDcBRx","cell_type":"markdown","source":"## Загрузка данных","metadata":{"id":"n7ivommDcBRx"}},{"id":"9J8JbAv9bizU","cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/gdrive/')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9J8JbAv9bizU","outputId":"e9c17fa6-0b94-43a7-9af2-f28635786550","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:17.593039Z","iopub.execute_input":"2025-04-06T09:21:17.593310Z","iopub.status.idle":"2025-04-06T09:21:17.596740Z","shell.execute_reply.started":"2025-04-06T09:21:17.593289Z","shell.execute_reply":"2025-04-06T09:21:17.595745Z"}},"outputs":[],"execution_count":1},{"id":"p-IbOGDFb7Vj","cell_type":"code","source":"# !mkdir -p ~/.kaggle\n# !cp /content/gdrive/MyDrive/kaggle.json ~/.kaggle/\n# !chmod 600 ~/.kaggle/kaggle.json","metadata":{"id":"p-IbOGDFb7Vj","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:17.617809Z","iopub.execute_input":"2025-04-06T09:21:17.618041Z","iopub.status.idle":"2025-04-06T09:21:17.620840Z","shell.execute_reply.started":"2025-04-06T09:21:17.618021Z","shell.execute_reply":"2025-04-06T09:21:17.620117Z"}},"outputs":[],"execution_count":2},{"id":"QuAGfiPicAVc","cell_type":"code","source":"# !kaggle competitions download -c journey-springfield","metadata":{"id":"QuAGfiPicAVc","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:17.627618Z","iopub.execute_input":"2025-04-06T09:21:17.627859Z","iopub.status.idle":"2025-04-06T09:21:17.633012Z","shell.execute_reply.started":"2025-04-06T09:21:17.627840Z","shell.execute_reply":"2025-04-06T09:21:17.632454Z"}},"outputs":[],"execution_count":3},{"id":"c4yX3wQlcIgu","cell_type":"code","source":"# !unzip journey-springfield.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4yX3wQlcIgu","outputId":"287c13b6-ea4c-4633-b840-825a640db6be","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:17.645187Z","iopub.execute_input":"2025-04-06T09:21:17.645373Z","iopub.status.idle":"2025-04-06T09:21:17.648276Z","shell.execute_reply.started":"2025-04-06T09:21:17.645357Z","shell.execute_reply":"2025-04-06T09:21:17.647625Z"}},"outputs":[],"execution_count":4},{"id":"b0apnvo4ciy7","cell_type":"markdown","source":"## Работа с датасетом","metadata":{"id":"b0apnvo4ciy7"}},{"id":"sXOt-1lpchZD","cell_type":"code","source":"import pickle\nimport numpy as np\nfrom skimage import io\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nfrom pathlib import Path\n\nfrom torchvision import transforms, models\nfrom multiprocessing.pool import ThreadPool\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\nimport torch\n\nimport pytorch_lightning as pl\n\nfrom matplotlib import colors, pyplot as plt\n%matplotlib inline\n","metadata":{"id":"sXOt-1lpchZD","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:17.654054Z","iopub.execute_input":"2025-04-06T09:21:17.654244Z","iopub.status.idle":"2025-04-06T09:21:27.785122Z","shell.execute_reply.started":"2025-04-06T09:21:17.654228Z","shell.execute_reply":"2025-04-06T09:21:27.784449Z"}},"outputs":[],"execution_count":5},{"id":"G6o5YkIZkxXi","cell_type":"markdown","source":"Для воспроизводимости","metadata":{"id":"G6o5YkIZkxXi"}},{"id":"srS_EmiwkeDY","cell_type":"code","source":"import torch\nimport random\nimport numpy as np\n\ndef set_seed(seed):\n    random.seed(seed)                  # Python\n    np.random.seed(seed)               # Numpy\n    torch.manual_seed(seed)            # PyTorch CPU\n    torch.cuda.manual_seed(seed)       # PyTorch GPU\n    torch.backends.cudnn.deterministic = True  # Для детерминированности на CUDA\n    torch.backends.cudnn.benchmark = False     # Для воспроизводимости\n\nset_seed(42)","metadata":{"id":"srS_EmiwkeDY","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:27.786100Z","iopub.execute_input":"2025-04-06T09:21:27.786432Z","iopub.status.idle":"2025-04-06T09:21:27.796050Z","shell.execute_reply.started":"2025-04-06T09:21:27.786414Z","shell.execute_reply":"2025-04-06T09:21:27.795251Z"}},"outputs":[],"execution_count":6},{"id":"0oekD6DzccS1","cell_type":"code","source":"# разные режимы датасета\nDATA_MODES = ['train', 'val', 'test']\n# все изображения будут масштабированы к размеру 224x224 px\nRESCALE_SIZE = 224\n# работаем на видеокарте\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"id":"0oekD6DzccS1","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:27.797320Z","iopub.execute_input":"2025-04-06T09:21:27.797726Z","iopub.status.idle":"2025-04-06T09:21:27.830350Z","shell.execute_reply.started":"2025-04-06T09:21:27.797693Z","shell.execute_reply":"2025-04-06T09:21:27.829790Z"}},"outputs":[],"execution_count":7},{"id":"RWu1DszrkAbg","cell_type":"markdown","source":"Добавим аугментации для train к кастомному классу датасета:\n\n- Случайный crop вместо детерминированного\n- случайный поворот на 25 градусов\n- случайный флип","metadata":{"id":"RWu1DszrkAbg"}},{"id":"vIakHhFLc70M","cell_type":"code","source":"class SimpsonsDataset(Dataset):\n    \"\"\"\n    Датасет с картинками, который паралельно подгружает их из папок\n    производит скалирование и превращение в торчевые тензоры\n    \"\"\"\n    def __init__(self, files, mode):\n        super().__init__()\n        # список файлов для загрузки\n        self.files = sorted(files)\n        # режим работы\n        self.mode = mode\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.files)\n\n        self.label_encoder = LabelEncoder()\n\n        if self.mode != 'test':\n            self.labels = [path.parent.name for path in self.files]\n            self.label_encoder.fit(self.labels)\n\n            with open('label_encoder.pkl', 'wb') as le_dump_file:\n                  pickle.dump(self.label_encoder, le_dump_file)\n\n    def __len__(self):\n        return self.len_\n\n    def load_sample(self, file):\n        image = Image.open(file)\n        image.load()\n        return image\n\n    def __getitem__(self, index):\n      # Выбираем нужную трансформацию\n      if self.mode == \"train\":\n          transform = transforms.Compose([\n              transforms.RandomHorizontalFlip(),\n              transforms.RandomRotation(25),\n              # transforms.RandomResizedCrop(RESCALE_SIZE),\n              # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n              transforms.ToTensor(),\n              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n          ])\n      else:\n          transform = transforms.Compose([\n              transforms.ToTensor(),\n              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n          ])\n\n      # Загружаем изображение\n      x = self.load_sample(self.files[index])\n      # Применяем подготовку (например, изменение размера)\n      x = self._prepare_sample(x)  # сейчас x — numpy.ndarray\n      # Преобразуем обратно в PIL.Image\n      x = Image.fromarray(x)\n      # Применяем цепочку трансформаций\n      x = transform(x)\n      # print(x)\n\n      if self.mode == 'test':\n          return x\n      else:\n          label = self.labels[index]\n          label_id = self.label_encoder.transform([label])\n          y = label_id.item()\n          return x, y\n\n\n    def _prepare_sample(self, image):\n      image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n      return np.array(image)","metadata":{"id":"vIakHhFLc70M","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:27.831310Z","iopub.execute_input":"2025-04-06T09:21:27.831564Z","iopub.status.idle":"2025-04-06T09:21:27.839706Z","shell.execute_reply.started":"2025-04-06T09:21:27.831545Z","shell.execute_reply":"2025-04-06T09:21:27.838877Z"}},"outputs":[],"execution_count":8},{"id":"jDV3jLj5k5gC","cell_type":"code","source":"def imshow(inp, title=None, plt_ax=plt, default=False):\n    \"\"\"Imshow для тензоров\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt_ax.imshow(inp)\n    if title is not None:\n        plt_ax.set_title(title)\n    plt_ax.grid(False)","metadata":{"id":"jDV3jLj5k5gC","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:27.840500Z","iopub.execute_input":"2025-04-06T09:21:27.840785Z","iopub.status.idle":"2025-04-06T09:21:27.854976Z","shell.execute_reply.started":"2025-04-06T09:21:27.840765Z","shell.execute_reply":"2025-04-06T09:21:27.854361Z"}},"outputs":[],"execution_count":9},{"id":"5SpU3m_hlBjS","cell_type":"code","source":"#определим директории с тренировочными и тестовыми файлами\nTRAIN_DIR = Path('/kaggle/input/journey-springfield/train/simpsons_dataset')\nTEST_DIR = Path('/kaggle/input/journey-springfield/testset/testset')","metadata":{"id":"5SpU3m_hlBjS","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:27.855643Z","iopub.execute_input":"2025-04-06T09:21:27.855864Z","iopub.status.idle":"2025-04-06T09:21:27.867974Z","shell.execute_reply.started":"2025-04-06T09:21:27.855847Z","shell.execute_reply":"2025-04-06T09:21:27.867371Z"}},"outputs":[],"execution_count":10},{"id":"a2z8V12zl1X1","cell_type":"code","source":"train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))","metadata":{"id":"a2z8V12zl1X1","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:21:27.868755Z","iopub.execute_input":"2025-04-06T09:21:27.868971Z","iopub.status.idle":"2025-04-06T09:22:09.562812Z","shell.execute_reply.started":"2025-04-06T09:21:27.868953Z","shell.execute_reply":"2025-04-06T09:22:09.562128Z"}},"outputs":[],"execution_count":11},{"id":"PZMQYvDTmD5z","cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_val_labels = [path.parent.name for path in train_val_files]\ntrain_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n                                          stratify=train_val_labels)","metadata":{"id":"PZMQYvDTmD5z","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:09.564769Z","iopub.execute_input":"2025-04-06T09:22:09.564992Z","iopub.status.idle":"2025-04-06T09:22:09.633207Z","shell.execute_reply.started":"2025-04-06T09:22:09.564974Z","shell.execute_reply":"2025-04-06T09:22:09.632603Z"}},"outputs":[],"execution_count":12},{"id":"c02f6ab0-099e-432c-a37b-fdf7b5e82822","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0b45-9fSoMRa","cell_type":"code","source":"val_dataset = SimpsonsDataset(val_files, mode='val')\ntrain_dataset = SimpsonsDataset(train_files, mode='train')","metadata":{"id":"0b45-9fSoMRa","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:09.634752Z","iopub.execute_input":"2025-04-06T09:22:09.635027Z","iopub.status.idle":"2025-04-06T09:22:09.782653Z","shell.execute_reply.started":"2025-04-06T09:22:09.634995Z","shell.execute_reply":"2025-04-06T09:22:09.782050Z"}},"outputs":[],"execution_count":13},{"id":"5d09ea70-0754-41e2-bf09-94097edb1225","cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import WeightedRandomSampler\n\nall_labels = [path.parent.name for path in train_files]\n# Находим уникальные метки и их количество\nunique_labels, counts = np.unique(all_labels, return_counts=True)\n\n# Вычисляем вес для каждого класса как обратную частоту\nclass_weights = {label: 1.0 / count for label, count in zip(unique_labels, counts)}\n\n# Применяем веса ко всем примерам\nsample_weights = np.array([class_weights[label] for label in all_labels])\n\n# Преобразуем в тензор\nsample_weights = torch.tensor(sample_weights, dtype=torch.float)\n\n# Создаем WeightedRandomSampler\nsampler = WeightedRandomSampler(\n    weights=sample_weights,\n    num_samples=len(sample_weights),\n    replacement=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:09.783405Z","iopub.execute_input":"2025-04-06T09:22:09.783725Z","iopub.status.idle":"2025-04-06T09:22:09.825645Z","shell.execute_reply.started":"2025-04-06T09:22:09.783693Z","shell.execute_reply":"2025-04-06T09:22:09.825089Z"}},"outputs":[],"execution_count":14},{"id":"75416378-a38c-437e-a80f-b37f03809413","cell_type":"code","source":"from torch.utils.data import DataLoader, WeightedRandomSampler\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler, num_workers = 4)\nval_loader = DataLoader(val_dataset, batch_size=128, num_workers = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:09.826310Z","iopub.execute_input":"2025-04-06T09:22:09.826498Z","iopub.status.idle":"2025-04-06T09:22:09.830564Z","shell.execute_reply.started":"2025-04-06T09:22:09.826482Z","shell.execute_reply":"2025-04-06T09:22:09.829701Z"}},"outputs":[],"execution_count":15},{"id":"JQqTnvTXoPAy","cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = train_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                train_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JQqTnvTXoPAy","outputId":"7ed748db-a9e0-418b-b7ce-acf1331e847b","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:09.831507Z","iopub.execute_input":"2025-04-06T09:22:09.831758Z"}},"outputs":[],"execution_count":null},{"id":"Rc0bqCld2n2X","cell_type":"markdown","source":"## Дополнительные функции для обучения\n\n\nБудем обучать через PyTorch Lightning и отслеживать через TensorBoard","metadata":{"id":"Rc0bqCld2n2X"}},{"id":"dbbb4e81-b229-455f-987f-325df431da5b","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nimport torchmetrics\n\n\n# LightningModule, где реализована логика обучения и валидации\nclass LitModel(pl.LightningModule):\n    def __init__(self, model, criterion, num_classes, lr=1e-3):\n        super().__init__()\n        self.model = model\n        self.criterion = criterion\n        self.lr = lr\n        self.num_classes = num_classes\n        \n        # Инициализация метрик (F1 - главная, а также Accuracy)\n        self.train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes, average=\"macro\")\n        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes, average=\"macro\")\n        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n    \n    def forward(self, x):\n        return self.model(x)\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.criterion(logits, y)\n        preds = torch.argmax(logits, dim=1)\n        \n        self.train_f1.update(preds, y)\n        self.train_acc.update(preds, y)\n        \n        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        # Здесь мы не логируем F1 на уровне шага, т.к. он считается на уровне эпохи\n        return loss\n    \n    def on_train_epoch_end(self, outputs = None):\n        train_f1 = self.train_f1.compute()\n        train_acc = self.train_acc.compute()\n        # Логгируем F1 как главную метрику, а также accuracy\n        self.log(\"train_f1\", train_f1, prog_bar=True)\n        self.log(\"train_acc\", train_acc, prog_bar=True)\n        self.train_f1.reset()\n        self.train_acc.reset()\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.criterion(logits, y)\n        preds = torch.argmax(logits, dim=1)\n        \n        self.val_f1.update(preds, y)\n        self.val_acc.update(preds, y)\n        \n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        return loss\n    \n    def on_validation_epoch_end(self, outputs = None):\n        val_f1 = self.val_f1.compute()\n        val_acc = self.val_acc.compute()\n        self.log(\"val_f1\", val_f1, prog_bar=True)\n        self.log(\"val_acc\", val_acc, prog_bar=True)\n        self.val_f1.reset()\n        self.val_acc.reset()\n    \n    def configure_optimizers(self):\n        # Формируем две группы параметров:\n        # 1. С весовым распадом (для всех, кроме batch norm и bias)\n        # 2. Без весового распада (batch norm и bias)\n        decay, no_decay = [], []\n        for name, param in self.named_parameters():\n            if not param.requires_grad:\n                continue\n            # Если параметр является bias или принадлежит слою batch norm, не применяем weight decay\n            if \"bias\" in name or \"bn\" in name or \"batchnorm\" in name.lower():\n                no_decay.append(param)\n            else:\n                decay.append(param)\n    \n        # Оптимизатор AdamW\n        optimizer = torch.optim.AdamW([\n            {\"params\": decay},\n            {\"params\": no_decay, \"weight_decay\": 0.0}\n        ], lr=self.lr)\n    \n        # Планировщик косинусного затухания\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n    \n        # Возвращаем оптимизатор и планировщик в формате словаря\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"interval\": \"epoch\",  # Применять после каждой эпохи\n                \"frequency\": 1,       # Обновлять каждые 1 эпоху\n                \"monitor\": \"val_loss\" # Мониторим валидационную ошибку (для ReduceLROnPlateau)\n            }\n        }\n","metadata":{"trusted":true,"execution":{"iopub.execute_input":"2025-04-06T09:22:11.890871Z","iopub.status.idle":"2025-04-06T09:22:11.909653Z","shell.execute_reply.started":"2025-04-06T09:22:11.890842Z","shell.execute_reply":"2025-04-06T09:22:11.908365Z"}},"outputs":[],"execution_count":17},{"id":"XSZNSlCpzbyK","cell_type":"markdown","source":"## ResNet18\n\n\nБудем пробовать с resnet18. Первые слои заморозим, оставим последний слой для обучения. Напишем отдельным классом.","metadata":{"id":"XSZNSlCpzbyK"}},{"id":"mHtMtN4J0PAz","cell_type":"code","source":"from torchvision.models import ResNet18_Weights\n\n\nmodels.resnet18(weights=ResNet18_Weights.DEFAULT)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHtMtN4J0PAz","outputId":"9ce6e98c-a96e-4d85-c379-02588466cc6c","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:11.910846Z","iopub.execute_input":"2025-04-06T09:22:11.911160Z","iopub.status.idle":"2025-04-06T09:22:12.511848Z","shell.execute_reply.started":"2025-04-06T09:22:11.911122Z","shell.execute_reply":"2025-04-06T09:22:12.510953Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 171MB/s]\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}],"execution_count":18},{"id":"f-u3025IxQ7f","cell_type":"code","source":"class SimpsonsResNet18(nn.Module):\n  def __init__(self, n_classes):\n    super().__init__()\n\n    self.base_model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n\n    # заморозка параметров\n    for param in self.base_model.parameters():\n      param.requires_grad = False\n\n    # разморозка последнего блока\n    for param in self.base_model.layer4.parameters():\n      param.requires_grad = True\n\n    # замена последнего блока на нужный классификатор\n    in_features = self.base_model.fc.in_features\n    self.base_model.fc = nn.Linear(in_features, n_classes)\n\n\n  def forward(self, x):\n    return self.base_model(x)","metadata":{"id":"f-u3025IxQ7f","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:12.512889Z","iopub.execute_input":"2025-04-06T09:22:12.513223Z","iopub.status.idle":"2025-04-06T09:22:12.519073Z","shell.execute_reply.started":"2025-04-06T09:22:12.513188Z","shell.execute_reply":"2025-04-06T09:22:12.518062Z"}},"outputs":[],"execution_count":19},{"id":"ieEs_gM35sdW","cell_type":"markdown","source":"### Обучение","metadata":{"id":"ieEs_gM35sdW"}},{"id":"7bv56dqx7pFt","cell_type":"code","source":"n_classes = len(np.unique(val_dataset.labels))\n\nmodel = SimpsonsResNet18(n_classes).to(DEVICE)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7bv56dqx7pFt","outputId":"85ed8bd1-2211-4f19-d095-59d22a1df902","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:12.520064Z","iopub.execute_input":"2025-04-06T09:22:12.520587Z","iopub.status.idle":"2025-04-06T09:22:12.971766Z","shell.execute_reply.started":"2025-04-06T09:22:12.520558Z","shell.execute_reply":"2025-04-06T09:22:12.971116Z"}},"outputs":[],"execution_count":20},{"id":"N01q3M_n-nxp","cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"id":"N01q3M_n-nxp","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:12.972490Z","iopub.execute_input":"2025-04-06T09:22:12.972790Z","iopub.status.idle":"2025-04-06T09:22:12.976466Z","shell.execute_reply.started":"2025-04-06T09:22:12.972767Z","shell.execute_reply":"2025-04-06T09:22:12.975726Z"}},"outputs":[],"execution_count":21},{"id":"3d713c94-812f-4d30-8116-68b65f5469db","cell_type":"code","source":"lit_model = LitModel(model=model, criterion=criterion, num_classes=n_classes, lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:12.977346Z","iopub.execute_input":"2025-04-06T09:22:12.977615Z","iopub.status.idle":"2025-04-06T09:22:12.993931Z","shell.execute_reply.started":"2025-04-06T09:22:12.977588Z","shell.execute_reply":"2025-04-06T09:22:12.993229Z"}},"outputs":[],"execution_count":22},{"id":"2cfde2b1-35bc-4934-972b-d82c1be853fd","cell_type":"code","source":"%reload_ext tensorboard\n%tensorboard --logdir tb_logs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:12.994643Z","iopub.execute_input":"2025-04-06T09:22:12.994919Z","iopub.status.idle":"2025-04-06T09:22:27.063089Z","shell.execute_reply.started":"2025-04-06T09:22:12.994899Z","shell.execute_reply":"2025-04-06T09:22:27.062291Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    "},"metadata":{}}],"execution_count":23},{"id":"b1992720-e5fc-42f6-b884-e0493d918c48","cell_type":"code","source":"from pytorch_lightning.callbacks import ModelCheckpoint\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor=\"val_f1\",      # метрика, по которой определяется лучшая модель\n    mode=\"max\",            # режим максимизации (так как F1 нужно увеличивать)\n    save_top_k=1,          # сохраняем только лучший чекпоинт\n    filename=\"{epoch:02d}-{val_f1:.4f}\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:40.768933Z","iopub.execute_input":"2025-04-06T09:22:40.769227Z","iopub.status.idle":"2025-04-06T09:22:40.773590Z","shell.execute_reply.started":"2025-04-06T09:22:40.769205Z","shell.execute_reply":"2025-04-06T09:22:40.772708Z"}},"outputs":[],"execution_count":26},{"id":"8ba6227c-bb55-48ba-8eb8-b5a62c28c87b","cell_type":"code","source":"from pytorch_lightning.loggers import TensorBoardLogger\n\n\nlogger = TensorBoardLogger(\"tb_logs\", name=\"simpsons_res_net18\")\n\n# Создаем Trainer\ntrainer = pl.Trainer(max_epochs=10, logger=logger, callbacks=[checkpoint_callback])\n\n# Запускаем обучение\ntrainer.fit(lit_model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:22:40.777517Z","iopub.execute_input":"2025-04-06T09:22:40.777787Z","iopub.status.idle":"2025-04-06T09:32:23.818260Z","shell.execute_reply.started":"2025-04-06T09:22:40.777756Z","shell.execute_reply":"2025-04-06T09:32:23.817452Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f6db3f390834ae9bf5ca02b66012f1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":27},{"id":"3r8Ot7QWqkVr","cell_type":"code","source":"label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))","metadata":{"id":"3r8Ot7QWqkVr","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:47.012458Z","iopub.execute_input":"2025-04-06T09:33:47.012809Z","iopub.status.idle":"2025-04-06T09:33:47.017025Z","shell.execute_reply.started":"2025-04-06T09:33:47.012781Z","shell.execute_reply":"2025-04-06T09:33:47.016121Z"}},"outputs":[],"execution_count":40},{"id":"SbpElhDlrkuQ","cell_type":"code","source":"def predict_one_sample(model, inputs, device=DEVICE):\n    \"\"\"Предсказание, для одной картинки\"\"\"\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        model.eval()\n        logit = model(inputs).cpu()\n        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n    return probs","metadata":{"id":"SbpElhDlrkuQ","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:47.024695Z","iopub.execute_input":"2025-04-06T09:33:47.024959Z","iopub.status.idle":"2025-04-06T09:33:47.034988Z","shell.execute_reply.started":"2025-04-06T09:33:47.024938Z","shell.execute_reply":"2025-04-06T09:33:47.034156Z"}},"outputs":[],"execution_count":41},{"id":"a532f198-475f-46ad-a9cf-68ad5cf3efdd","cell_type":"code","source":"# Определяем устройство\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Переносим модель на устройство\nmodel = model.to(device)\n\n# Получаем изображение из датасета\nrandom_characters = int(np.random.uniform(0, 1000))\nex_img, true_label = val_dataset[random_characters]\n\n# Перемещаем изображение на то же устройство\nex_img = ex_img.unsqueeze(0).to(device)\n\n# Предсказание\nprobs_im = predict_one_sample(model, ex_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:47.036140Z","iopub.execute_input":"2025-04-06T09:33:47.036424Z","iopub.status.idle":"2025-04-06T09:33:47.063593Z","shell.execute_reply.started":"2025-04-06T09:33:47.036395Z","shell.execute_reply":"2025-04-06T09:33:47.062996Z"}},"outputs":[],"execution_count":42},{"id":"fe9d36bc-f033-424e-a0fb-1590856658a0","cell_type":"code","source":"def predict(model, test_loader):\n    \"\"\"\n    Функция выполняет предсказание классов для тестового набора данных с использованием обученной модели.\n\n    Эта функция принимает модель и загрузчик тестовых данных, применяет модель к\n    изображениям и возвращает вероятности предсказанных классов.\n\n    Параметры:\n    ----------\n    model : nn.Module\n        Обученная модель, которая будет использоваться для предсказания.\n        Должна быть экземпляром класса PyTorch `nn.Module`.\n\n    test_loader : DataLoader\n        Загрузчик данных, который предоставляет батчи входных данных для тестирования.\n        Должен возвращать тензоры входных данных.\n\n    Возвращает:\n    ----------\n    numpy.ndarray\n        Массив вероятностей предсказанных классов для каждого примера в тестовом наборе.\n        Размерность массива будет (N, C), где N - количество примеров, а C - количество классов.\n    \"\"\"\n\n    with torch.no_grad():\n        logits = []\n\n        for inputs in test_loader:\n            inputs = inputs.to(DEVICE)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n\n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:47.064991Z","iopub.execute_input":"2025-04-06T09:33:47.065202Z","iopub.status.idle":"2025-04-06T09:33:47.070011Z","shell.execute_reply.started":"2025-04-06T09:33:47.065183Z","shell.execute_reply":"2025-04-06T09:33:47.069192Z"}},"outputs":[],"execution_count":43},{"id":"6aed55b2-3a4b-4786-9ee2-df0032c30745","cell_type":"code","source":"idxs = list(map(int, np.random.uniform(0,1000, 20)))\nimgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n\nprobs_ims = predict(model, imgs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:47.070965Z","iopub.execute_input":"2025-04-06T09:33:47.071213Z","iopub.status.idle":"2025-04-06T09:33:47.260052Z","shell.execute_reply.started":"2025-04-06T09:33:47.071169Z","shell.execute_reply":"2025-04-06T09:33:47.259180Z"}},"outputs":[],"execution_count":44},{"id":"0c39bf47-81eb-49da-8d57-db01e05d923b","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7322b318-f9dd-41d0-bcd3-aac8e321f77c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"46640eba-ed12-439a-bac6-d70215b54262","cell_type":"code","source":"y_pred = np.argmax(probs_ims,-1)\n\nactual_labels = [val_dataset[id][1] for id in idxs]\n\npreds_class = [label_encoder.classes_[i] for i in y_pred]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:47.260883Z","iopub.execute_input":"2025-04-06T09:33:47.261111Z","iopub.status.idle":"2025-04-06T09:33:47.360086Z","shell.execute_reply.started":"2025-04-06T09:33:47.261092Z","shell.execute_reply":"2025-04-06T09:33:47.359261Z"}},"outputs":[],"execution_count":45},{"id":"xqRwQOkRrhIb","cell_type":"code","source":"import matplotlib.patches as patches\nfrom matplotlib.font_manager import FontProperties\n\nfig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n\n\n\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)\n\n    actual_text = \"Actual : {}\".format(img_label)\n\n    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n    font0 = FontProperties()\n    font = font0.copy()\n    font.set_family(\"fantasy\")\n    prob_pred = predict_one_sample(model, im_val.unsqueeze(0))\n    predicted_proba = np.max(prob_pred)*100\n    y_pred = np.argmax(prob_pred)\n\n    predicted_label = label_encoder.classes_[y_pred]\n    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n\n    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xqRwQOkRrhIb","outputId":"58987639-4d1c-4e86-8793-c44bd4bdc692","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:47.360847Z","iopub.execute_input":"2025-04-06T09:33:47.361096Z"}},"outputs":[],"execution_count":null},{"id":"uWGL-s21r5Lt","cell_type":"code","source":"test_dataset = SimpsonsDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\nprobs = predict(model, test_loader)\n\n\npreds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\ntest_filenames = [path.name for path in test_dataset.files]\n","metadata":{"id":"uWGL-s21r5Lt","trusted":true,"execution":{"iopub.execute_input":"2025-04-06T09:33:49.299949Z","iopub.status.idle":"2025-04-06T09:33:53.607529Z","shell.execute_reply.started":"2025-04-06T09:33:49.299910Z","shell.execute_reply":"2025-04-06T09:33:53.606749Z"}},"outputs":[],"execution_count":47},{"id":"G4Hi6JJJsETX","cell_type":"code","source":"import pandas as pd\nmy_submit = pd.read_csv(\"/kaggle/input/journey-springfield/sample_submission.csv\")\nmy_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\nmy_submit.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"G4Hi6JJJsETX","outputId":"96404263-e967-47bd-9f6b-090e24cbf53e","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:33:53.609656Z","iopub.execute_input":"2025-04-06T09:33:53.609967Z","iopub.status.idle":"2025-04-06T09:33:53.620700Z","shell.execute_reply.started":"2025-04-06T09:33:53.609944Z","shell.execute_reply":"2025-04-06T09:33:53.619880Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"           Id                Expected\n0    img0.jpg            nelson_muntz\n1    img1.jpg            bart_simpson\n2   img10.jpg            ned_flanders\n3  img100.jpg            chief_wiggum\n4  img101.jpg  apu_nahasapeemapetilon","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Expected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img0.jpg</td>\n      <td>nelson_muntz</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img1.jpg</td>\n      <td>bart_simpson</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img10.jpg</td>\n      <td>ned_flanders</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img100.jpg</td>\n      <td>chief_wiggum</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img101.jpg</td>\n      <td>apu_nahasapeemapetilon</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":48},{"id":"U9F0ENX2sH83","cell_type":"code","source":"my_submit.to_csv('res_net_baseline_new_sheduler.csv', index=False)","metadata":{"id":"U9F0ENX2sH83","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:34:19.971706Z","iopub.execute_input":"2025-04-06T09:34:19.972035Z","iopub.status.idle":"2025-04-06T09:34:19.978349Z","shell.execute_reply.started":"2025-04-06T09:34:19.972005Z","shell.execute_reply":"2025-04-06T09:34:19.977317Z"}},"outputs":[],"execution_count":51},{"id":"8SqHSoZ3uYyA","cell_type":"code","source":"torch.save(model.state_dict(), 'resnet18_weights_new_sheduler.pth')\n","metadata":{"id":"8SqHSoZ3uYyA","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:40:32.716210Z","iopub.execute_input":"2025-04-06T09:40:32.716508Z","iopub.status.idle":"2025-04-06T09:40:32.787062Z","shell.execute_reply.started":"2025-04-06T09:40:32.716483Z","shell.execute_reply":"2025-04-06T09:40:32.786350Z"}},"outputs":[],"execution_count":52},{"id":"midOnM6Vv6DP","cell_type":"code","source":"\n","metadata":{"id":"midOnM6Vv6DP","trusted":true},"outputs":[],"execution_count":null}]}